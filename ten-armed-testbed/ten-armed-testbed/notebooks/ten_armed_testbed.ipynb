{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 10-armed Testbed",
   "id": "5c99de12c6afa2cb"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-13T17:01:47.586505Z",
     "start_time": "2025-05-13T17:01:46.072542Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), 'src')))\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import trange\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bandit import Bandit\n",
    "matplotlib.use('Agg')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "def simulate(runs, times, bandits):\n",
    "    # region Summary\n",
    "    \"\"\"\n",
    "    For any learning method, we can measure its performance and behavior as it improves with experience over 1000 time steps\n",
    "    when applied to 1 of the bandit problems. This makes up 1 run. Repeating this for 2000 independent runs, each with a different\n",
    "    bandit problem, we obtained measures of the learning algorithm‚Äôs average behavior.\n",
    "    :param runs: Number of runs\n",
    "    :param times: Number of times\n",
    "    :param bandits: Bandit problems\n",
    "    :return: Optimal action count mean and reward mean\n",
    "    \"\"\"\n",
    "    # endregion Summary\n",
    "\n",
    "    # region Body\n",
    "\n",
    "    # Prepare a matrix filled with 0s for rewards\n",
    "    rewards = np.zeros((len(bandits), runs, times))\n",
    "\n",
    "    # Prepare a matrix filled with 0s for optimal action counts that has the same shape as rewards matrix\n",
    "    optimal_actions_counts = np.zeros(rewards.shape)\n",
    "\n",
    "    # For every bandit\n",
    "    for i , bandit in enumerate(bandits):\n",
    "\n",
    "        # for every run\n",
    "        for run in trange(runs):\n",
    "            # initialize bandit\n",
    "            bandit.initialize()\n",
    "            # for every time step\n",
    "            for time in range(times):\n",
    "                # select an action\n",
    "                action = bandit.act()\n",
    "\n",
    "\n",
    "                # get the reward\n",
    "                rewards[i, run, time] = bandit.step(action)\n",
    "\n",
    "                # if the selected action is optimal for bandit\n",
    "                if action == bandit.optimal_action:\n",
    "                    # change the corresponding 0 in the optimal action counts matrix to 1\n",
    "                    optimal_actions_counts[i, run, time] = 1\n",
    "\n",
    "    return optimal_actions_counts.mean(axis=1), rewards.mean(axis=1)\n",
    "\n",
    "    # endregion Body"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T17:01:48.203666Z",
     "start_time": "2025-05-13T17:01:48.194716Z"
    }
   },
   "id": "be09fd89ebd40d84",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Reward Distribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4088366f60e51478"
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot an example reward distribution\n",
    "plt.violinplot(dataset=np.random.randn(200, 10) + np.random.randn(10))\n",
    "plt.title(\"Figure 2.1\")\n",
    "plt.xlabel(\"Action\")\n",
    "plt.ylabel(\"Reward distribution\")\n",
    "plt.savefig(\"../generated_images/figure_2_1.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T13:56:48.569900Z",
     "start_time": "2025-05-11T13:56:47.895543Z"
    }
   },
   "id": "8ed1daafa4064440",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Greedy Action Selection VS Œµ-greedy Action Selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef67eb7574c5d2b1"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of epsilons with 0, 0.1 and 0.01 values\n",
    "epsilons = [0, 0.1, 0.01]\n",
    "\n",
    "\n",
    "# Create a list of bandits (1 bandit for every epsilon) where every bandit uses sample-average method\n",
    "bandits = [Bandit(epsilon=epsilon, use_sample_averages=True) for epsilon in epsilons]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T13:56:49.699124Z",
     "start_time": "2025-05-11T13:56:49.692796Z"
    }
   },
   "id": "6a180bc790c31e65",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "runs = 2000\n",
    "\n",
    "# Define number of times\n",
    "times = 1000\n",
    "\n",
    "# Simulate optimal action counts and rewards\n",
    "optimal_actions_counts, rewards_mean = simulate(runs, times, bandits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:00:12.911456Z",
     "start_time": "2025-05-11T13:56:51.026337Z"
    }
   },
   "id": "683805477a8d4606",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:02<00:00, 32.23it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:04<00:00, 31.18it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:15<00:00, 26.47it/s]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "plt.figure(figsize = (10, 20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:00:40.541082Z",
     "start_time": "2025-05-11T14:00:40.504280Z"
    }
   },
   "id": "e1a86ca5f4aefa2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x2000 with 0 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "for epsilon, rewards in zip(epsilons, rewards_mean):\n",
    "    plt.plot(rewards, label=r\"$\\epsilon = %.02f$\" % epsilon)\n",
    "plt.title(\"Figure 2.2\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Average reward\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:00:41.616488Z",
     "start_time": "2025-05-11T14:00:41.530579Z"
    }
   },
   "id": "5536109f4e591e72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11918d3db20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "plt.subplot(2, 1, 2)\n",
    "for epsilon, counts in zip(epsilons, optimal_actions_counts):\n",
    "    plt.plot(counts, label=r\"$\\epsilon = %.02f$\" % epsilon)\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"% Optimal action\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:00:43.320816Z",
     "start_time": "2025-05-11T14:00:43.291906Z"
    }
   },
   "id": "2e6157d53f01223f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x119196a8770>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "plt.savefig(\"../generated_images/figure_2_2.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:00:45.781654Z",
     "start_time": "2025-05-11T14:00:44.795028Z"
    }
   },
   "id": "ca9dfed4b31f4579",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Optimistic Initial Values VS Realistic Initial Values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0c5945f58dd0dee"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of 2 bandits where:\n",
    "# 1. 1st bandit: Œµ = 0, ùëÑ_1(ùëé) = 5, ùõº = 0.1,\n",
    "# 2. 2nd bandit: Œµ = 0.1, ùëÑ_1(ùëé) = 0, ùõº = 0.1\n",
    "bandits = [Bandit(epsilon = 0, initial_action_value_estimates = 5, step_size = 0.1),\n",
    "           Bandit(epsilon = 0.1, initial_action_value_estimates = 0, step_size = 0.1)]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:00:47.102053Z",
     "start_time": "2025-05-11T14:00:47.097372Z"
    }
   },
   "id": "50d647979ced258a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "runs = 2000\n",
    "\n",
    "# Define number of times\n",
    "times = 1000\n",
    "\n",
    "# Simulate optimal action counts\n",
    "optimal_actions_counts, _ = simulate(runs, times, bandits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:02:18.762002Z",
     "start_time": "2025-05-11T14:00:48.392454Z"
    }
   },
   "id": "3116e78a4c90c435",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:53<00:00, 37.10it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:36<00:00, 54.89it/s]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "plt.plot(optimal_actions_counts[0], label = \"$epsilons = 0 , Q1 = 5$\")\n",
    "plt.plot(optimal_actions_counts[1], label = \"$epsilons = 0.1 , Q1 = 0$\")\n",
    "plt.title(\"Figure 2.3\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"% Optimal action\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../generated_images/figure_2_3.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:02:25.020852Z",
     "start_time": "2025-05-11T14:02:24.261520Z"
    }
   },
   "id": "d1ae633f8632eed5",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Upper-Confidence-Bound (UCB) Action Selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7473708c239f1d0"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of 2 bandits where:\n",
    "# 1. 1st bandit: Œµ = 0, ùëê = 2, uses sample-average method,\n",
    "# 2. 2nd bandit: Œµ = 0.1, uses sample-average method\n",
    "bandits = [Bandit(epsilon = 0, confidence_level = 2, use_sample_averages = True),\n",
    "           Bandit(epsilon = 0.1, use_sample_averages = True)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:02:26.301594Z",
     "start_time": "2025-05-11T14:02:26.295080Z"
    }
   },
   "id": "1993531b4fe5feb2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "runs = 2000\n",
    "\n",
    "# Define number of times\n",
    "times = 1000\n",
    "\n",
    "# Simulate average rewards\n",
    "_,average_rewards = simulate(runs, times, bandits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:04:14.042233Z",
     "start_time": "2025-05-11T14:02:27.548191Z"
    }
   },
   "id": "6e1fed28f6812c2e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:59<00:00, 33.77it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:47<00:00, 42.33it/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "plt.plot(average_rewards[0], label = \"UCB $c = 2$\")\n",
    "plt.plot(average_rewards[1], label = r\"$\\epsilon-greedy$ $\\epsilon = 0.1$\")\n",
    "plt.title(\"Figure 2.4\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Average reward\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../generated_images/figure_2_4.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d4db60f0153c024",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Gradient Bandit Algorithms (GBA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5cb31b7d224bbba"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of 4 bandits where:\n",
    "# 1. 1st bandit: uses GBA, ùõº = 0.1, uses average reward as baseline for GBA, expects true reward of 4,\n",
    "# 2. 2nd bandit: uses GBA, ùõº = 0.1, doesn't use average reward as baseline for GBA, expects true reward of 4,\n",
    "# 3. 3rd bandit: uses GBA, ùõº = 0.4, uses average reward as baseline for GBA, expects true reward of 4,\n",
    "# 4. 4th bandit: uses GBA, ùõº = 0.4, doesn't use average reward as baseline for GBA, expects true reward of 4\n",
    "bandits = [Bandit(use_gradient = True, step_size = 0.1, use_gradient_baseline = True, true_expected_reward = 4),\n",
    "           Bandit(use_gradient = True, step_size = 0.1, use_gradient_baseline = False, true_expected_reward = 4),\n",
    "           Bandit(use_gradient = True, step_size = 0.4, use_gradient_baseline = True, true_expected_reward = 4),\n",
    "           Bandit(use_gradient = True, step_size  = 0.4, use_gradient_baseline = False, true_expected_reward = 4)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1453e8fb0e6a32f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "runs = 2000\n",
    "\n",
    "# Define number of times\n",
    "times = 1000\n",
    "\n",
    "# Simulate optimal action counts\n",
    "optimal_actions_counts, _ = simulate(runs, times, bandits)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79a2acb7e523f0a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Labels\n",
    "labels = [r\"$\\alpha = 0.1$, with baseline \", r\"$\\alpha = 0.1$, without baseline\",\n",
    "          r\"$\\alpha = 0.4$, with baseline\", r\"$\\alpha = 0.4$, without baseline\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67282242fae58cb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "for i in range(len(bandits)):\n",
    "    plt.plot(optimal_actions_counts[i], label = labels[i])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2281e1a4dc8f1b9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.title(\"Figure 2.5\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"% Optimal action\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../generated_images/figure_2.5.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "974417449ca9770c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Comparison of Bandit Algorithms with Different Parameters\n",
    "\n"
   ],
   "id": "3d44eddfddcb9faa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:04:42.232367Z",
     "start_time": "2025-05-11T14:04:42.226272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define labels for each method\n",
    "labels = ['epsilon-greedy', 'gradient bandit',\n",
    "          'UCB', 'optimistic initialization']\n"
   ],
   "id": "bbf300a21862f0bc",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:19:53.366132Z",
     "start_time": "2025-05-11T14:19:53.354703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define bandit generators with respective parameters\n",
    "generators = [lambda epsilon: Bandit(epsilon=epsilon, use_sample_averages=True),\n",
    "              lambda alpha: Bandit(use_gradient=True, step_size=alpha, use_gradient_baseline=True),\n",
    "              lambda coef: Bandit(epsilon=0, confidence_level=coef, use_sample_averages=True),\n",
    "              lambda initial: Bandit(epsilon=0, initial_action_value_estimates=initial, step_size=0.1)]\n",
    "\n",
    "\n",
    "# Define parameter ranges as powers of 2\n",
    "parameters = [np.arange(-7, -1, dtype=float),\n",
    "              np.arange(-5, 2, dtype=float),\n",
    "              np.arange(-4, 3, dtype=float),\n",
    "              np.arange(-2, 3, dtype=float)]\n"
   ],
   "id": "a9da827db39f6ecc",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:19:54.815100Z",
     "start_time": "2025-05-11T14:19:54.806663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create bandits for each method and parameter\n",
    "bandits = []\n",
    "for generator, parameter in zip(generators, parameters):\n",
    "    for param in parameter:\n",
    "        bandits.append(generator(pow(2, param)))"
   ],
   "id": "3166e5312e61ed9d",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:48:57.014100Z",
     "start_time": "2025-05-11T14:19:57.037287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_, average_rewards = simulate(runs=2000, times=1000, bandits=bandits)\n",
    "rewards = np.mean(average_rewards, axis=1)\n",
    "\n",
    "print(rewards.shape)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "i = 0\n",
    "for label, parameter in zip(labels, parameters):\n",
    "    l = len(parameter)\n",
    "    if len(rewards[i:i + l]) == l:\n",
    "        plt.plot(parameter, rewards[i:i + l], label=label)\n",
    "    else:\n",
    "        print(f\"Warning: Mismatch in length for {label}.\")\n",
    "\n",
    "    i += l\n",
    "\n",
    "plt.xlabel('Parameter ($2^x$)')\n",
    "plt.ylabel('Average reward')\n",
    "plt.legend()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"../generated_images/figure_2_6.png\")\n",
    "plt.close()"
   ],
   "id": "7f03d5d4fb9ad891",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:03<00:00, 31.61it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:58<00:00, 33.91it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:57<00:00, 34.79it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:53<00:00, 37.28it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:51<00:00, 38.58it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:59<00:00, 33.53it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:32<00:00, 21.64it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:10<00:00, 28.21it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:57<00:00, 34.95it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:03<00:00, 31.27it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:00<00:00, 33.24it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:03<00:00, 31.34it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:59<00:00, 33.71it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:56<00:00, 35.56it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:23<00:00, 23.91it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:22<00:00, 24.24it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:18<00:00, 25.50it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:01<00:00, 32.62it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:21<00:00, 24.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:22<00:00, 24.21it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:04<00:00, 31.11it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [02:11<00:00, 15.17it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:34<00:00, 21.20it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:55<00:00, 35.96it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:51<00:00, 38.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25,)\n"
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
