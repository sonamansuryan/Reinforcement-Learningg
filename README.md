## NPUA Reinforcement Learning Course Projects

### Overview  
This repository includes a collection of projects developed during the Reinforcement Learning (RL) course at the National Polytechnic University of Armenia (NPUA). The projects integrate theoretical knowledge with practical applications, aiming to develop a deep understanding of decision-making systems. The work is based on the latest methodologies in reinforcement learning research.

---

### Key Projects Overview

#### ✅ Project 1: Tic-Tac-Toe Game  
**Goal:** Implement a classic Tic-Tac-Toe environment and train an RL agent to play optimally through self-play.  
**Features:**  
- Tabular value function learning  
- Training through episode simulations  
- Play against the trained agent

---

#### ✅ Project 2: Multi-Armed Bandit Problem  
**Objective:** Explore the exploration-exploitation dilemma through simulation of bandit algorithms.  
**Strategies Implemented:**  
- ε-greedy  
- Upper Confidence Bound (UCB)  
- Gradient Bandits  
**Analysis:**  
- Comparison between optimistic and realistic initial values  
- Tracking average rewards and optimal action percentages

---

#### ✅ Project 3: Markov Decision Process (MDP) in Grid-World  
**Description:** Implementation of a finite MDP in a grid-world environment.  
**Highlights:**  
- Custom reward structure with special states (A and B)  
- Equiprobable random policy evaluation using Bellman Expectation Equation  
- Visualization of state-value function under a fixed policy

---

#### ✅ Project 4: Dynamic Programming (DP) in Grid-World  
**Focus:** Iterative policy evaluation, improvement, and policy iteration in a small grid-world setup.  
**Key Components:**  
- In-place and out-of-place value updates  
- Equiprobable and greedy policies  
- Demonstration of policy improvement and convergence  
- Implementation of Bellman Expectation and Optimality Equations

---

#### ✅ Project 5: Gambler’s Problem – Value Iteration Approach  
**Description:** Solving the Gambler’s Problem using value iteration in a finite MDP setup.  
**Highlights:**  
- Implementation of Value Iteration algorithm  
- Exploration of how different stake choices affect the probability of reaching the goal  
- Application of Bellman Optimality Equation  
- Visualization of optimal policy and value function

